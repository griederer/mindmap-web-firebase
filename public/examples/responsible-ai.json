{
  "projectId": "responsible-ai",
  "metadata": {
    "title": "Responsible AI",
    "description": "Comprehensive framework for understanding and implementing responsible artificial intelligence",
    "version": "1.0.0",
    "createdAt": 1730500000000,
    "updatedAt": 1730500000000,
    "author": "NODEM",
    "tags": ["AI", "Ethics", "Governance", "Risk Management", "Compliance"],
    "views": {
      "mindmap": {
        "enabled": true
      }
    }
  },
  "mindmap": {
    "rootNodeId": "responsible-ai-root",
    "nodes": {
      "responsible-ai-root": {
        "id": "responsible-ai-root",
        "title": "Responsible AI",
        "description": "Framework for ethical AI development ensuring fairness, transparency, accountability, privacy, safety, and human oversight throughout the AI lifecycle.",
        "level": 0,
        "parentId": null,
        "children": ["definition", "ai-risks", "nist-framework", "eu-ai-act", "pwc-framework"],
        "position": { "x": 100, "y": 300 },
        "isExpanded": true,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#3B82F6", "icon": "ðŸ¤–" }
      },

      "definition": {
        "id": "definition",
        "title": "Definition",
        "description": "Core definition and principles of Responsible AI",
        "level": 1,
        "parentId": "responsible-ai-root",
        "children": ["def-fairness", "def-transparency", "def-accountability", "def-privacy", "def-safety", "def-human-oversight"],
        "position": { "x": 400, "y": 50 },
        "isExpanded": true,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#8B5CF6" }
      },
      "def-fairness": {
        "id": "def-fairness",
        "title": "Fairness",
        "description": "Eliminating bias in data, algorithms, and outcomes to ensure equitable treatment across demographics",
        "level": 2,
        "parentId": "definition",
        "children": ["fairness-bias", "fairness-equity", "fairness-inclusion"],
        "position": { "x": 700, "y": 20 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#8B5CF6" }
      },
      "fairness-bias": {
        "id": "fairness-bias",
        "title": "Bias Mitigation",
        "description": "Techniques to detect and eliminate bias in training data and model outputs",
        "level": 3,
        "parentId": "def-fairness",
        "children": ["bias-detection", "bias-remediation"],
        "position": { "x": 1000, "y": 0 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#8B5CF6" }
      },
      "bias-detection": {
        "id": "bias-detection",
        "title": "Bias Detection",
        "description": "Automated tools and statistical methods to identify discriminatory patterns in data and model predictions",
        "level": 4,
        "parentId": "fairness-bias",
        "children": [],
        "position": { "x": 1300, "y": -20 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#8B5CF6" }
      },
      "bias-remediation": {
        "id": "bias-remediation",
        "title": "Bias Remediation",
        "description": "Techniques like re-sampling, re-weighting, and adversarial debiasing to correct identified biases",
        "level": 4,
        "parentId": "fairness-bias",
        "children": [],
        "position": { "x": 1300, "y": 20 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#8B5CF6" }
      },
      "fairness-equity": {
        "id": "fairness-equity",
        "title": "Equity Metrics",
        "description": "Quantitative measures like demographic parity, equalized odds, and calibration to assess fairness",
        "level": 3,
        "parentId": "def-fairness",
        "children": [],
        "position": { "x": 1000, "y": 40 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#8B5CF6" }
      },
      "fairness-inclusion": {
        "id": "fairness-inclusion",
        "title": "Inclusive Design",
        "description": "Ensuring AI systems work equitably across diverse user groups and contexts",
        "level": 3,
        "parentId": "def-fairness",
        "children": [],
        "position": { "x": 1000, "y": 80 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#8B5CF6" }
      },
      "def-transparency": {
        "id": "def-transparency",
        "title": "Transparency",
        "description": "Making AI decision-making processes understandable and explainable to stakeholders",
        "level": 2,
        "parentId": "definition",
        "children": ["transparency-explainability", "transparency-documentation"],
        "position": { "x": 700, "y": 100 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#8B5CF6" }
      },
      "transparency-explainability": {
        "id": "transparency-explainability",
        "title": "Explainability Techniques",
        "description": "Methods like SHAP, LIME, attention mechanisms to explain model predictions",
        "level": 3,
        "parentId": "def-transparency",
        "children": [],
        "position": { "x": 1000, "y": 90 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#8B5CF6" }
      },
      "transparency-documentation": {
        "id": "transparency-documentation",
        "title": "Model Documentation",
        "description": "Model cards, datasheets, and audit trails documenting AI system design and performance",
        "level": 3,
        "parentId": "def-transparency",
        "children": [],
        "position": { "x": 1000, "y": 130 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#8B5CF6" }
      },
      "def-accountability": {
        "id": "def-accountability",
        "title": "Accountability",
        "description": "Clear ownership and responsibility for AI system behaviors and impacts",
        "level": 2,
        "parentId": "definition",
        "children": [],
        "position": { "x": 700, "y": 160 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#8B5CF6" }
      },
      "def-privacy": {
        "id": "def-privacy",
        "title": "Privacy",
        "description": "Protecting personal data and ensuring compliance with data protection regulations",
        "level": 2,
        "parentId": "definition",
        "children": [],
        "position": { "x": 700, "y": 190 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#8B5CF6" }
      },
      "def-safety": {
        "id": "def-safety",
        "title": "Safety & Security",
        "description": "Safeguards against misuse, adversarial attacks, and unintended consequences",
        "level": 2,
        "parentId": "definition",
        "children": [],
        "position": { "x": 700, "y": 220 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#8B5CF6" }
      },
      "def-human-oversight": {
        "id": "def-human-oversight",
        "title": "Human Oversight",
        "description": "Maintaining meaningful human control over critical AI decisions",
        "level": 2,
        "parentId": "definition",
        "children": [],
        "position": { "x": 700, "y": 250 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#8B5CF6" }
      },

      "ai-risks": {
        "id": "ai-risks",
        "title": "AI Risks",
        "description": "Comprehensive taxonomy of risks introduced by AI systems",
        "level": 1,
        "parentId": "responsible-ai-root",
        "children": ["technical-risks", "operational-risks", "societal-risks", "regulatory-risks"],
        "position": { "x": 400, "y": 150 },
        "isExpanded": true,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#EF4444" }
      },
      "technical-risks": {
        "id": "technical-risks",
        "title": "Technical Risks",
        "description": "Risks arising from AI system design, implementation, and performance",
        "level": 2,
        "parentId": "ai-risks",
        "children": ["risk-bias", "risk-explainability", "risk-security", "risk-performance"],
        "position": { "x": 700, "y": 120 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#EF4444" }
      },
      "risk-bias": {
        "id": "risk-bias",
        "title": "Bias & Discrimination",
        "description": "Models perpetuating societal inequities in hiring, lending, healthcare, criminal justice",
        "level": 3,
        "parentId": "technical-risks",
        "children": ["bias-training-data", "bias-algorithmic", "bias-feedback-loops"],
        "position": { "x": 1000, "y": 80 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#EF4444" }
      },
      "bias-training-data": {
        "id": "bias-training-data",
        "title": "Training Data Bias",
        "description": "Historical biases embedded in training datasets leading to discriminatory predictions",
        "level": 4,
        "parentId": "risk-bias",
        "children": [],
        "position": { "x": 1300, "y": 60 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#EF4444" }
      },
      "bias-algorithmic": {
        "id": "bias-algorithmic",
        "title": "Algorithmic Bias",
        "description": "Bias introduced by model architecture, optimization objectives, or hyperparameter choices",
        "level": 4,
        "parentId": "risk-bias",
        "children": [],
        "position": { "x": 1300, "y": 90 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#EF4444" }
      },
      "bias-feedback-loops": {
        "id": "bias-feedback-loops",
        "title": "Feedback Loop Amplification",
        "description": "AI decisions creating feedback loops that amplify initial biases over time",
        "level": 4,
        "parentId": "risk-bias",
        "children": [],
        "position": { "x": 1300, "y": 120 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#EF4444" }
      },
      "risk-explainability": {
        "id": "risk-explainability",
        "title": "Lack of Explainability",
        "description": "Black box models making decisions that cannot be understood or challenged",
        "level": 3,
        "parentId": "technical-risks",
        "children": [],
        "position": { "x": 1000, "y": 140 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#EF4444" }
      },
      "risk-security": {
        "id": "risk-security",
        "title": "Security Vulnerabilities",
        "description": "Adversarial attacks, data poisoning, model extraction exploiting AI systems",
        "level": 3,
        "parentId": "technical-risks",
        "children": ["security-adversarial", "security-poisoning", "security-extraction"],
        "position": { "x": 1000, "y": 170 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#EF4444" }
      },
      "security-adversarial": {
        "id": "security-adversarial",
        "title": "Adversarial Attacks",
        "description": "Crafted inputs designed to fool AI models into making incorrect predictions",
        "level": 4,
        "parentId": "risk-security",
        "children": [],
        "position": { "x": 1300, "y": 150 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#EF4444" }
      },
      "security-poisoning": {
        "id": "security-poisoning",
        "title": "Data Poisoning",
        "description": "Injecting malicious data into training sets to corrupt model behavior",
        "level": 4,
        "parentId": "risk-security",
        "children": [],
        "position": { "x": 1300, "y": 180 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#EF4444" }
      },
      "security-extraction": {
        "id": "security-extraction",
        "title": "Model Extraction",
        "description": "Reverse-engineering proprietary models through query-based attacks",
        "level": 4,
        "parentId": "risk-security",
        "children": [],
        "position": { "x": 1300, "y": 210 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#EF4444" }
      },
      "risk-performance": {
        "id": "risk-performance",
        "title": "Performance Degradation",
        "description": "Models failing in real-world conditions differing from training environments",
        "level": 3,
        "parentId": "technical-risks",
        "children": [],
        "position": { "x": 1000, "y": 230 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#EF4444" }
      },
      "operational-risks": {
        "id": "operational-risks",
        "title": "Operational Risks",
        "description": "Risks from AI deployment, integration, and organizational practices",
        "level": 2,
        "parentId": "ai-risks",
        "children": ["risk-overreliance", "risk-privacy-violations", "risk-robustness"],
        "position": { "x": 700, "y": 260 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#EF4444" }
      },
      "risk-overreliance": {
        "id": "risk-overreliance",
        "title": "Over-reliance on Automation",
        "description": "Excessive trust in AI leading to diminished human judgment and oversight",
        "level": 3,
        "parentId": "operational-risks",
        "children": [],
        "position": { "x": 1000, "y": 240 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#EF4444" }
      },
      "risk-privacy-violations": {
        "id": "risk-privacy-violations",
        "title": "Data Privacy Violations",
        "description": "Inappropriate processing of sensitive data or enabling re-identification",
        "level": 3,
        "parentId": "operational-risks",
        "children": [],
        "position": { "x": 1000, "y": 270 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#EF4444" }
      },
      "risk-robustness": {
        "id": "risk-robustness",
        "title": "Lack of Robustness",
        "description": "Unpredictable behavior in edge cases or when facing novel inputs",
        "level": 3,
        "parentId": "operational-risks",
        "children": [],
        "position": { "x": 1000, "y": 300 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#EF4444" }
      },
      "societal-risks": {
        "id": "societal-risks",
        "title": "Societal Risks",
        "description": "Broader impacts on society, workforce, and power structures",
        "level": 2,
        "parentId": "ai-risks",
        "children": ["risk-displacement", "risk-autonomy", "risk-power"],
        "position": { "x": 700, "y": 330 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#EF4444" }
      },
      "risk-displacement": {
        "id": "risk-displacement",
        "title": "Job Displacement",
        "description": "Automation eliminating roles without adequate workforce transition support",
        "level": 3,
        "parentId": "societal-risks",
        "children": [],
        "position": { "x": 1000, "y": 310 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#EF4444" }
      },
      "risk-autonomy": {
        "id": "risk-autonomy",
        "title": "Erosion of Autonomy",
        "description": "AI-driven micro-targeting and manipulation undermining individual agency",
        "level": 3,
        "parentId": "societal-risks",
        "children": [],
        "position": { "x": 1000, "y": 340 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#EF4444" }
      },
      "risk-power": {
        "id": "risk-power",
        "title": "Concentration of Power",
        "description": "AI capabilities entrenching dominance of large technology companies",
        "level": 3,
        "parentId": "societal-risks",
        "children": [],
        "position": { "x": 1000, "y": 370 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#EF4444" }
      },
      "regulatory-risks": {
        "id": "regulatory-risks",
        "title": "Regulatory & Legal Risks",
        "description": "Compliance and accountability challenges in evolving regulatory landscape",
        "level": 2,
        "parentId": "ai-risks",
        "children": ["risk-noncompliance", "risk-liability"],
        "position": { "x": 700, "y": 390 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#EF4444" }
      },
      "risk-noncompliance": {
        "id": "risk-noncompliance",
        "title": "Non-compliance",
        "description": "Failure to meet emerging AI regulations resulting in fines and reputational damage",
        "level": 3,
        "parentId": "regulatory-risks",
        "children": [],
        "position": { "x": 1000, "y": 380 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#EF4444" }
      },
      "risk-liability": {
        "id": "risk-liability",
        "title": "Liability Gaps",
        "description": "Unclear responsibility for AI-caused harms creating legal uncertainties",
        "level": 3,
        "parentId": "regulatory-risks",
        "children": [],
        "position": { "x": 1000, "y": 410 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#EF4444" }
      },

      "nist-framework": {
        "id": "nist-framework",
        "title": "NIST AI RMF",
        "description": "U.S. National Institute of Standards AI Risk Management Framework with 4 core functions",
        "level": 1,
        "parentId": "responsible-ai-root",
        "children": ["nist-govern", "nist-map", "nist-measure", "nist-manage"],
        "position": { "x": 400, "y": 300 },
        "isExpanded": true,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#10B981" }
      },
      "nist-govern": {
        "id": "nist-govern",
        "title": "GOVERN",
        "description": "Establish organizational culture, policies, and structures for responsible AI",
        "level": 2,
        "parentId": "nist-framework",
        "children": ["govern-culture", "govern-policies", "govern-workforce"],
        "position": { "x": 700, "y": 260 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#10B981" }
      },
      "govern-culture": {
        "id": "govern-culture",
        "title": "AI Risk Culture",
        "description": "Fostering organizational awareness and commitment to responsible AI practices",
        "level": 3,
        "parentId": "nist-govern",
        "children": [],
        "position": { "x": 1000, "y": 240 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#10B981" }
      },
      "govern-policies": {
        "id": "govern-policies",
        "title": "Policies & Standards",
        "description": "Establishing AI-specific policies for ethics, risk management, and development",
        "level": 3,
        "parentId": "nist-govern",
        "children": [],
        "position": { "x": 1000, "y": 270 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#10B981" }
      },
      "govern-workforce": {
        "id": "govern-workforce",
        "title": "Workforce Competency",
        "description": "Building AI ethics and risk management capabilities across teams",
        "level": 3,
        "parentId": "nist-govern",
        "children": [],
        "position": { "x": 1000, "y": 300 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#10B981" }
      },
      "nist-map": {
        "id": "nist-map",
        "title": "MAP",
        "description": "Understand organizational context and categorize AI risks",
        "level": 2,
        "parentId": "nist-framework",
        "children": ["map-context", "map-categorize", "map-tolerance"],
        "position": { "x": 700, "y": 320 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#10B981" }
      },
      "map-context": {
        "id": "map-context",
        "title": "System Context",
        "description": "Identifying and documenting AI system context and intended use",
        "level": 3,
        "parentId": "nist-map",
        "children": [],
        "position": { "x": 1000, "y": 310 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#10B981" }
      },
      "map-categorize": {
        "id": "map-categorize",
        "title": "Risk Categorization",
        "description": "Categorizing AI risks and mapping to potential harms",
        "level": 3,
        "parentId": "nist-map",
        "children": [],
        "position": { "x": 1000, "y": 340 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#10B981" }
      },
      "map-tolerance": {
        "id": "map-tolerance",
        "title": "Risk Tolerance",
        "description": "Assessing organizational risk tolerance and prioritizing mitigation",
        "level": 3,
        "parentId": "nist-map",
        "children": [],
        "position": { "x": 1000, "y": 370 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#10B981" }
      },
      "nist-measure": {
        "id": "nist-measure",
        "title": "MEASURE",
        "description": "Analyze, assess, and benchmark AI risks and impacts",
        "level": 2,
        "parentId": "nist-framework",
        "children": ["measure-metrics", "measure-testing", "measure-monitoring"],
        "position": { "x": 700, "y": 390 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#10B981" }
      },
      "measure-metrics": {
        "id": "measure-metrics",
        "title": "Risk Metrics",
        "description": "Implementing metrics for fairness, explainability, and robustness",
        "level": 3,
        "parentId": "nist-measure",
        "children": [],
        "position": { "x": 1000, "y": 380 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#10B981" }
      },
      "measure-testing": {
        "id": "measure-testing",
        "title": "System Testing",
        "description": "Testing AI systems for bias, accuracy, and reliability",
        "level": 3,
        "parentId": "nist-measure",
        "children": [],
        "position": { "x": 1000, "y": 410 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#10B981" }
      },
      "measure-monitoring": {
        "id": "measure-monitoring",
        "title": "Continuous Monitoring",
        "description": "Ongoing evaluation and tracking of risk trends over time",
        "level": 3,
        "parentId": "nist-measure",
        "children": [],
        "position": { "x": 1000, "y": 440 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#10B981" }
      },
      "nist-manage": {
        "id": "nist-manage",
        "title": "MANAGE",
        "description": "Prioritize, respond to, and monitor AI risks",
        "level": 2,
        "parentId": "nist-framework",
        "children": ["manage-treatment", "manage-incident", "manage-improvement"],
        "position": { "x": 700, "y": 460 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#10B981" }
      },
      "manage-treatment": {
        "id": "manage-treatment",
        "title": "Risk Treatment",
        "description": "Implementing plans to avoid, mitigate, transfer, or accept risks",
        "level": 3,
        "parentId": "nist-manage",
        "children": [],
        "position": { "x": 1000, "y": 450 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#10B981" }
      },
      "manage-incident": {
        "id": "manage-incident",
        "title": "Incident Response",
        "description": "Establishing procedures for responding to AI incidents",
        "level": 3,
        "parentId": "nist-manage",
        "children": [],
        "position": { "x": 1000, "y": 480 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#10B981" }
      },
      "manage-improvement": {
        "id": "manage-improvement",
        "title": "Continuous Improvement",
        "description": "Enabling feedback loops for ongoing risk management enhancement",
        "level": 3,
        "parentId": "nist-manage",
        "children": [],
        "position": { "x": 1000, "y": 510 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#10B981" }
      },

      "eu-ai-act": {
        "id": "eu-ai-act",
        "title": "EU AI Act",
        "description": "World's first comprehensive AI regulation with risk-based classification system",
        "level": 1,
        "parentId": "responsible-ai-root",
        "children": ["eu-unacceptable", "eu-high-risk", "eu-limited-risk", "eu-minimal-risk"],
        "position": { "x": 400, "y": 450 },
        "isExpanded": true,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#F59E0B" }
      },
      "eu-unacceptable": {
        "id": "eu-unacceptable",
        "title": "Unacceptable Risk (Prohibited)",
        "description": "AI systems posing clear threats to safety, livelihoods, or fundamental rights",
        "level": 2,
        "parentId": "eu-ai-act",
        "children": ["eu-social-scoring", "eu-biometric", "eu-manipulation", "eu-emotion"],
        "position": { "x": 700, "y": 420 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#F59E0B" }
      },
      "eu-social-scoring": {
        "id": "eu-social-scoring",
        "title": "Social Scoring",
        "description": "Government social scoring systems evaluating trustworthiness of individuals",
        "level": 3,
        "parentId": "eu-unacceptable",
        "children": [],
        "position": { "x": 1000, "y": 400 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#F59E0B" }
      },
      "eu-biometric": {
        "id": "eu-biometric",
        "title": "Real-time Biometric ID",
        "description": "Real-time biometric identification in public spaces (with limited exceptions)",
        "level": 3,
        "parentId": "eu-unacceptable",
        "children": [],
        "position": { "x": 1000, "y": 430 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#F59E0B" }
      },
      "eu-manipulation": {
        "id": "eu-manipulation",
        "title": "Manipulative AI",
        "description": "AI targeting vulnerabilities to manipulate behavior causing harm",
        "level": 3,
        "parentId": "eu-unacceptable",
        "children": [],
        "position": { "x": 1000, "y": 460 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#F59E0B" }
      },
      "eu-emotion": {
        "id": "eu-emotion",
        "title": "Emotion Recognition",
        "description": "Emotion recognition in workplaces and educational institutions",
        "level": 3,
        "parentId": "eu-unacceptable",
        "children": [],
        "position": { "x": 1000, "y": 490 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#F59E0B" }
      },
      "eu-high-risk": {
        "id": "eu-high-risk",
        "title": "High-Risk AI Systems",
        "description": "AI in critical areas where errors could cause significant harm",
        "level": 2,
        "parentId": "eu-ai-act",
        "children": ["eu-hr-biometric", "eu-hr-infrastructure", "eu-hr-employment", "eu-hr-services", "eu-hr-law"],
        "position": { "x": 700, "y": 500 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#F59E0B" }
      },
      "eu-hr-biometric": {
        "id": "eu-hr-biometric",
        "title": "Biometric Identification",
        "description": "Remote biometric identification and categorization of natural persons",
        "level": 3,
        "parentId": "eu-high-risk",
        "children": [],
        "position": { "x": 1000, "y": 480 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#F59E0B" }
      },
      "eu-hr-infrastructure": {
        "id": "eu-hr-infrastructure",
        "title": "Critical Infrastructure",
        "description": "AI managing critical infrastructure (water, gas, electricity, transport)",
        "level": 3,
        "parentId": "eu-high-risk",
        "children": [],
        "position": { "x": 1000, "y": 510 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#F59E0B" }
      },
      "eu-hr-employment": {
        "id": "eu-hr-employment",
        "title": "Employment & HR",
        "description": "AI for recruitment, promotion, termination, and worker management",
        "level": 3,
        "parentId": "eu-high-risk",
        "children": [],
        "position": { "x": 1000, "y": 540 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#F59E0B" }
      },
      "eu-hr-services": {
        "id": "eu-hr-services",
        "title": "Essential Services",
        "description": "AI for credit scoring, insurance pricing, and benefit allocation",
        "level": 3,
        "parentId": "eu-high-risk",
        "children": [],
        "position": { "x": 1000, "y": 570 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#F59E0B" }
      },
      "eu-hr-law": {
        "id": "eu-hr-law",
        "title": "Law Enforcement & Justice",
        "description": "AI in law enforcement, migration, asylum, border control, and justice administration",
        "level": 3,
        "parentId": "eu-high-risk",
        "children": [],
        "position": { "x": 1000, "y": 600 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#F59E0B" }
      },
      "eu-limited-risk": {
        "id": "eu-limited-risk",
        "title": "Limited Risk (Transparency)",
        "description": "AI systems requiring user awareness of AI interaction",
        "level": 2,
        "parentId": "eu-ai-act",
        "children": ["eu-lr-chatbots", "eu-lr-deepfakes"],
        "position": { "x": 700, "y": 620 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#F59E0B" }
      },
      "eu-lr-chatbots": {
        "id": "eu-lr-chatbots",
        "title": "Chatbots",
        "description": "Conversational AI requiring disclosure of non-human interaction",
        "level": 3,
        "parentId": "eu-limited-risk",
        "children": [],
        "position": { "x": 1000, "y": 610 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#F59E0B" }
      },
      "eu-lr-deepfakes": {
        "id": "eu-lr-deepfakes",
        "title": "Deepfakes & Synthetic Media",
        "description": "AI-generated content requiring clear labeling and disclosure",
        "level": 3,
        "parentId": "eu-limited-risk",
        "children": [],
        "position": { "x": 1000, "y": 640 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#F59E0B" }
      },
      "eu-minimal-risk": {
        "id": "eu-minimal-risk",
        "title": "Minimal Risk (No Obligations)",
        "description": "Most AI systems with voluntary adherence to codes of conduct",
        "level": 2,
        "parentId": "eu-ai-act",
        "children": [],
        "position": { "x": 700, "y": 670 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#F59E0B" }
      },

      "pwc-framework": {
        "id": "pwc-framework",
        "title": "PwC Framework",
        "description": "Comprehensive operational framework for implementing responsible AI",
        "level": 1,
        "parentId": "responsible-ai-root",
        "children": ["pwc-governance", "pwc-risk-assessment", "pwc-fairness", "pwc-transparency", "pwc-privacy", "pwc-safety", "pwc-lifecycle"],
        "position": { "x": 400, "y": 600 },
        "isExpanded": true,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-governance": {
        "id": "pwc-governance",
        "title": "Governance & Accountability",
        "description": "Establishing AI oversight structures and clear responsibilities",
        "level": 2,
        "parentId": "pwc-framework",
        "children": ["pwc-ethics-board", "pwc-roles", "pwc-policies", "pwc-third-party"],
        "position": { "x": 700, "y": 540 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-ethics-board": {
        "id": "pwc-ethics-board",
        "title": "AI Ethics Board",
        "description": "Cross-functional oversight body with executive sponsorship for AI governance",
        "level": 3,
        "parentId": "pwc-governance",
        "children": [],
        "position": { "x": 1000, "y": 520 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-roles": {
        "id": "pwc-roles",
        "title": "Roles & Responsibilities",
        "description": "Defining accountability across Data Scientists, Product Owners, Risk, Legal, Business Units",
        "level": 3,
        "parentId": "pwc-governance",
        "children": [],
        "position": { "x": 1000, "y": 550 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-policies": {
        "id": "pwc-policies",
        "title": "Policies & Standards",
        "description": "AI-specific policies covering ethics, risk management, data use, model development",
        "level": 3,
        "parentId": "pwc-governance",
        "children": [],
        "position": { "x": 1000, "y": 580 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-third-party": {
        "id": "pwc-third-party",
        "title": "Third-Party Management",
        "description": "Extending responsible AI requirements to vendors and partners",
        "level": 3,
        "parentId": "pwc-governance",
        "children": [],
        "position": { "x": 1000, "y": 610 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-risk-assessment": {
        "id": "pwc-risk-assessment",
        "title": "Risk Assessment",
        "description": "Systematic identification and evaluation of AI risks",
        "level": 2,
        "parentId": "pwc-framework",
        "children": ["pwc-inventory", "pwc-taxonomy", "pwc-impact-assessments"],
        "position": { "x": 700, "y": 620 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-inventory": {
        "id": "pwc-inventory",
        "title": "Use Case Inventory",
        "description": "Comprehensive catalog of AI systems with risk ratings",
        "level": 3,
        "parentId": "pwc-risk-assessment",
        "children": [],
        "position": { "x": 1000, "y": 610 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-taxonomy": {
        "id": "pwc-taxonomy",
        "title": "Risk Taxonomy",
        "description": "Classifying risks across fairness, transparency, privacy, security, safety, robustness",
        "level": 3,
        "parentId": "pwc-risk-assessment",
        "children": [],
        "position": { "x": 1000, "y": 640 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-impact-assessments": {
        "id": "pwc-impact-assessments",
        "title": "AI Impact Assessments",
        "description": "Evaluating potential harms to individuals, groups, and society for high-risk use cases",
        "level": 3,
        "parentId": "pwc-risk-assessment",
        "children": [],
        "position": { "x": 1000, "y": 670 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-fairness": {
        "id": "pwc-fairness",
        "title": "Fairness & Bias Mitigation",
        "description": "Detecting and remediating bias throughout AI lifecycle",
        "level": 2,
        "parentId": "pwc-framework",
        "children": ["pwc-data-quality", "pwc-audits", "pwc-fairness-metrics"],
        "position": { "x": 700, "y": 690 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-data-quality": {
        "id": "pwc-data-quality",
        "title": "Data Quality Controls",
        "description": "Processes to detect and remediate biased training data",
        "level": 3,
        "parentId": "pwc-fairness",
        "children": [],
        "position": { "x": 1000, "y": 680 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-audits": {
        "id": "pwc-audits",
        "title": "Algorithmic Audits",
        "description": "Testing models for discriminatory outcomes across protected attributes",
        "level": 3,
        "parentId": "pwc-fairness",
        "children": [],
        "position": { "x": 1000, "y": 710 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-fairness-metrics": {
        "id": "pwc-fairness-metrics",
        "title": "Fairness Metrics",
        "description": "Quantitative criteria like demographic parity and equalized odds",
        "level": 3,
        "parentId": "pwc-fairness",
        "children": [],
        "position": { "x": 1000, "y": 740 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-transparency": {
        "id": "pwc-transparency",
        "title": "Transparency & Explainability",
        "description": "Making AI decisions interpretable and challengeable",
        "level": 2,
        "parentId": "pwc-framework",
        "children": ["pwc-model-explainability", "pwc-model-cards", "pwc-audit-trails"],
        "position": { "x": 700, "y": 760 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-model-explainability": {
        "id": "pwc-model-explainability",
        "title": "Model Explainability",
        "description": "Implementing SHAP, LIME, attention mechanisms to explain predictions",
        "level": 3,
        "parentId": "pwc-transparency",
        "children": [],
        "position": { "x": 1000, "y": 750 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-model-cards": {
        "id": "pwc-model-cards",
        "title": "Model Cards",
        "description": "Documenting model purpose, training data, performance, limitations, intended use",
        "level": 3,
        "parentId": "pwc-transparency",
        "children": [],
        "position": { "x": 1000, "y": 780 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-audit-trails": {
        "id": "pwc-audit-trails",
        "title": "Audit Trails",
        "description": "Comprehensive logs of model development, validation, deployment decisions",
        "level": 3,
        "parentId": "pwc-transparency",
        "children": [],
        "position": { "x": 1000, "y": 810 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-privacy": {
        "id": "pwc-privacy",
        "title": "Privacy & Data Protection",
        "description": "Embedding privacy protections throughout AI systems",
        "level": 2,
        "parentId": "pwc-framework",
        "children": ["pwc-privacy-design", "pwc-minimization", "pwc-anonymization"],
        "position": { "x": 700, "y": 830 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-privacy-design": {
        "id": "pwc-privacy-design",
        "title": "Privacy by Design",
        "description": "Embedding privacy protections into AI architecture from inception",
        "level": 3,
        "parentId": "pwc-privacy",
        "children": [],
        "position": { "x": 1000, "y": 820 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-minimization": {
        "id": "pwc-minimization",
        "title": "Data Minimization",
        "description": "Collecting only data necessary for defined AI purposes",
        "level": 3,
        "parentId": "pwc-privacy",
        "children": [],
        "position": { "x": 1000, "y": 850 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-anonymization": {
        "id": "pwc-anonymization",
        "title": "Anonymization Techniques",
        "description": "Applying anonymization and pseudonymization to protect personal data",
        "level": 3,
        "parentId": "pwc-privacy",
        "children": [],
        "position": { "x": 1000, "y": 880 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-safety": {
        "id": "pwc-safety",
        "title": "Safety & Robustness",
        "description": "Ensuring AI systems are secure and reliable",
        "level": 2,
        "parentId": "pwc-framework",
        "children": ["pwc-adversarial-testing", "pwc-validation", "pwc-monitoring"],
        "position": { "x": 700, "y": 900 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-adversarial-testing": {
        "id": "pwc-adversarial-testing",
        "title": "Adversarial Testing",
        "description": "Testing against adversarial attacks and edge cases",
        "level": 3,
        "parentId": "pwc-safety",
        "children": [],
        "position": { "x": 1000, "y": 890 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-validation": {
        "id": "pwc-validation",
        "title": "Model Validation",
        "description": "Rigorous validation processes before production deployment",
        "level": 3,
        "parentId": "pwc-safety",
        "children": [],
        "position": { "x": 1000, "y": 920 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-monitoring": {
        "id": "pwc-monitoring",
        "title": "Drift Detection",
        "description": "Monitoring model performance and detecting data/concept drift",
        "level": 3,
        "parentId": "pwc-safety",
        "children": [],
        "position": { "x": 1000, "y": 950 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-lifecycle": {
        "id": "pwc-lifecycle",
        "title": "Lifecycle Management",
        "description": "Managing responsible AI throughout entire system lifecycle",
        "level": 2,
        "parentId": "pwc-framework",
        "children": ["pwc-design", "pwc-development", "pwc-deployment", "pwc-monitoring-phase"],
        "position": { "x": 700, "y": 970 },
        "isExpanded": false,
        "isVisible": true,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-design": {
        "id": "pwc-design",
        "title": "Design Phase",
        "description": "Integrating responsible AI considerations into ideation and design",
        "level": 3,
        "parentId": "pwc-lifecycle",
        "children": [],
        "position": { "x": 1000, "y": 960 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-development": {
        "id": "pwc-development",
        "title": "Development Phase",
        "description": "Applying fairness, transparency, robustness testing during development",
        "level": 3,
        "parentId": "pwc-lifecycle",
        "children": [],
        "position": { "x": 1000, "y": 990 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-deployment": {
        "id": "pwc-deployment",
        "title": "Deployment Phase",
        "description": "Pre-production reviews and approvals by AI Ethics Board",
        "level": 3,
        "parentId": "pwc-lifecycle",
        "children": [],
        "position": { "x": 1000, "y": 1020 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      },
      "pwc-monitoring-phase": {
        "id": "pwc-monitoring-phase",
        "title": "Monitoring Phase",
        "description": "Post-deployment monitoring dashboards tracking key risk indicators",
        "level": 3,
        "parentId": "pwc-lifecycle",
        "children": [],
        "position": { "x": 1000, "y": 1050 },
        "isExpanded": false,
        "isVisible": false,
        "createdAt": 1730500000000,
        "updatedAt": 1730500000000,
        "metadata": { "color": "#6366F1" }
      }
    }
  }
}
